{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1d2273",
   "metadata": {},
   "source": [
    "# Parkinson's Disease Classification with Hyperparameter Tuning\n",
    "\n",
    "This notebook performs an end-to-end machine learning analysis to classify Parkinson's disease based on a set of biomedical voice measurements.\n",
    "\n",
    "The process includes:\n",
    "1.  **Data Loading and Preprocessing**: Fetching the dataset, splitting it, and scaling features.\n",
    "2.  **Model Training**: Using `GridSearchCV` to find the best hyperparameters for several classification models, including a PyTorch-based Artificial Neural Network (ANN).\n",
    "3.  **Evaluation**: Comparing models based on F1-score, accuracy, and other metrics.\n",
    "4.  **Visualization**: Generating plots for model comparison, confusion matrices, ROC curves, and feature importance.\n",
    "5.  **Interpretability**: Analyzing feature importances to understand which factors are most predictive.\n",
    "6.  **Model Saving**: Saving the best-performing model and the feature scaler for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263bf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Required Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import skorch\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    f1_score, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# PyTorch and skorch for the Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa488a48",
   "metadata": {},
   "source": [
    "### PyTorch MLP Model Definition\n",
    "This class defines a simple Multi-Layer Perceptron (MLP) using PyTorch. It includes `BatchNorm1d` and `Dropout` layers to help prevent overfitting, which is common in models with many parameters. The network is designed for tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214e3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Small MLP for tabular inputs with BatchNorm+Dropout to reduce overfitting.\"\"\"\n",
    "    def __init__(self, in_dim: int, hidden: Tuple[int, int] = (256, 128), dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        h1, h2 = hidden\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, h1),\n",
    "            nn.BatchNorm1d(h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.BatchNorm1d(h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(h2, 1)  # single logit\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # skorch handles numpy-to-tensor conversion, but we ensure it's float32\n",
    "        x = x.float() \n",
    "        return self.net(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833bb9b",
   "metadata": {},
   "source": [
    "### 2. Setup and Data Preparation\n",
    "- An output directory is created to store all results.\n",
    "- The Parkinson's dataset is loaded from the UCI Machine Learning Repository.\n",
    "- Features (`X`) and the target variable (`y`) are separated.\n",
    "- The data is split into training and testing sets.\n",
    "- `StandardScaler` is used to normalize the features, which is crucial for distance-based algorithms and neural networks.\n",
    "- Data types are converted to `float32` to be compatible with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bcd76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results and figures will be saved in the 'parkinsons_analysis_results_gridsearch' directory.\n"
     ]
    }
   ],
   "source": [
    "# Setup Output Directory\n",
    "output_dir = 'parkinsons_analysis_results_gridsearch'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"All results and figures will be saved in the '{output_dir}' directory.\")\n",
    "\n",
    "# Data Loading and Preprocessing\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\"\n",
    "df = pd.read_csv(url)\n",
    "X = df.drop(['name', 'status'], axis=1)\n",
    "y = df['status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=99, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X.columns = df.drop(['name', 'status'], axis=1).columns\n",
    "\n",
    "# Convert data types for PyTorch/skorch\n",
    "X_train_scaled = X_train_scaled.astype(np.float32)\n",
    "X_test_scaled = X_test_scaled.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7ac6b",
   "metadata": {},
   "source": [
    "### 3. Define Parameter Grids for GridSearchCV\n",
    "This dictionary contains the hyperparameter search spaces for each model. `GridSearchCV` will exhaustively test all combinations to find the best ones based on the F1-score. The `ANN (PyTorch)` grid includes parameters like learning rate, epochs, and network architecture (`module__hidden`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849336a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'max_iter': [4000]\n",
    "    },\n",
    "    \"K-Nearest Neighbors\": {\n",
    "        'n_neighbors': list(range(1, 21)),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 5, 7, 10],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'probability': [True]\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        'var_smoothing': np.logspace(-9, -5, 10)\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 250, 500],\n",
    "        'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators':    [100, 300, 500],\n",
    "        'learning_rate':   [0.01, 0.05, 0.1],\n",
    "        'max_depth':       [3, 5, 7],\n",
    "        'min_child_weight':[1, 3, 5],\n",
    "        'subsample':       [0.7, 0.9, 1.0],\n",
    "        'colsample_bytree':[0.7, 0.9, 1.0]\n",
    "    },\n",
    "    \"ANN (PyTorch)\": {\n",
    "        'lr': [1e-4, 1e-3, 1e-2],\n",
    "        'max_epochs': [100, 300],\n",
    "        'batch_size': [16, 32],\n",
    "        'optimizer__weight_decay': [1e-5, 1e-4],\n",
    "        'module__hidden': [(128, 64), (256, 128)],\n",
    "        'module__dropout': [0.1, 0.2, 0.3]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd1463",
   "metadata": {},
   "source": [
    "### 4. Perform GridSearchCV for Each Model\n",
    "This is the core of the analysis. The code iterates through a list of models, including the `NeuralNetClassifier` from `skorch` which wraps our PyTorch `MLP`.\n",
    "\n",
    "For each model:\n",
    "1.  An instance is created. The PyTorch model is configured with early stopping to prevent overfitting and improve efficiency.\n",
    "2.  `GridSearchCV` is run with 5-fold cross-validation, optimizing for the `f1_weighted` score.\n",
    "3.  The best estimator is saved, and its performance is evaluated on the test set.\n",
    "4.  Metrics like F1-score, accuracy, precision, recall, and AUC-ROC are calculated and stored.\n",
    "5.  A detailed classification report is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a232731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running GridSearchCV for Logistic Regression ---\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Parameters found for Logistic Regression: {'C': 1, 'class_weight': None, 'max_iter': 4000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "\n",
      "--- Running GridSearchCV for K-Nearest Neighbors ---\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best Parameters found for Logistic Regression: {'C': 1, 'class_weight': None, 'max_iter': 4000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "\n",
      "--- Running GridSearchCV for K-Nearest Neighbors ---\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best Parameters found for K-Nearest Neighbors: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Best Parameters found for K-Nearest Neighbors: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "\n",
      "--- Running GridSearchCV for Decision Tree ---\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "\n",
      "--- Running GridSearchCV for Decision Tree ---\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Parameters found for Decision Tree: {'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "\n",
      "--- Running GridSearchCV for Support Vector Machine ---\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters found for Decision Tree: {'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "\n",
      "--- Running GridSearchCV for Support Vector Machine ---\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters found for Support Vector Machine: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf', 'probability': True}\n",
      "\n",
      "--- Running GridSearchCV for Naive Bayes ---\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Parameters found for Naive Bayes: {'var_smoothing': 1e-09}\n",
      "\n",
      "--- Running GridSearchCV for Random Forest ---\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Parameters found for Support Vector Machine: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf', 'probability': True}\n",
      "\n",
      "--- Running GridSearchCV for Naive Bayes ---\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Parameters found for Naive Bayes: {'var_smoothing': 1e-09}\n",
      "\n",
      "--- Running GridSearchCV for Random Forest ---\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Parameters found for Random Forest: {'class_weight': None, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "--- Running GridSearchCV for XGBoost ---\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best Parameters found for Random Forest: {'class_weight': None, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "--- Running GridSearchCV for XGBoost ---\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madha\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [08:32:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters found for XGBoost: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.7}\n",
      "\n",
      "--- Running GridSearchCV for ANN (PyTorch) ---\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Parameters found for ANN (PyTorch): {'batch_size': 32, 'lr': 0.01, 'max_epochs': 100, 'module__dropout': 0.1, 'module__hidden': (256, 128), 'optimizer__weight_decay': 1e-05}\n",
      "Best Parameters found for ANN (PyTorch): {'batch_size': 32, 'lr': 0.01, 'max_epochs': 100, 'module__dropout': 0.1, 'module__hidden': (256, 128), 'optimizer__weight_decay': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "model_performance_summary = []\n",
    "all_classification_reports = \"\"\n",
    "svm_grid_search_results = None # To store SVM grid results\n",
    "\n",
    "model_list = [\n",
    "    (\"Logistic Regression\", LogisticRegression), \n",
    "    (\"K-Nearest Neighbors\", KNeighborsClassifier), \n",
    "    (\"Decision Tree\", DecisionTreeClassifier), \n",
    "    (\"Support Vector Machine\", SVC),\n",
    "    (\"Naive Bayes\", GaussianNB),\n",
    "    (\"Random Forest\", RandomForestClassifier),\n",
    "    (\"XGBoost\", XGBClassifier),\n",
    "    (\"ANN (PyTorch)\", NeuralNetClassifier)\n",
    "]\n",
    "\n",
    "INPUT_DIM = X_train_scaled.shape[1]\n",
    "\n",
    "for name, model_class in model_list:\n",
    "    print(f\"\\n--- Running GridSearchCV for {name} ---\")\n",
    "    \n",
    "    if name == \"Support Vector Machine\":\n",
    "        model = model_class(random_state=42)\n",
    "    elif name in [\"K-Nearest Neighbors\", \"Naive Bayes\"]:\n",
    "        model = model_class()\n",
    "    elif name == \"Random Forest\":\n",
    "        model = model_class(random_state=42, n_jobs=-1)\n",
    "    elif name == \"XGBoost\":\n",
    "        model = model_class(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    elif name == \"ANN (PyTorch)\":\n",
    "        # skorch wrapper for PyTorch model\n",
    "        model = NeuralNetClassifier(\n",
    "            module=MLP,\n",
    "            module__in_dim=INPUT_DIM,\n",
    "            criterion=nn.BCEWithLogitsLoss,\n",
    "            optimizer=torch.optim.Adam,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            verbose=0, # Suppress skorch's verbosity\n",
    "            callbacks=[('early_stop', skorch.callbacks.EarlyStopping(patience=40, monitor='valid_loss'))]\n",
    "        )\n",
    "    else:\n",
    "        model = model_class(random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, \n",
    "                               param_grid=param_grids[name], \n",
    "                               cv=5, \n",
    "                               scoring='f1_weighted', \n",
    "                               n_jobs=-1, \n",
    "                               verbose=1,\n",
    "                               refit=True) \n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    if name == \"Support Vector Machine\":\n",
    "        svm_grid_search_results = grid_search\n",
    "    \n",
    "    print(f\"Best Parameters found for {name}: {grid_search.best_params_}\")\n",
    "    \n",
    "    y_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "    \n",
    "    if hasattr(grid_search.best_estimator_, \"predict_proba\"):\n",
    "        y_pred_proba_raw = grid_search.best_estimator_.predict_proba(X_test_scaled)\n",
    "        if name == \"ANN (PyTorch)\":\n",
    "            y_pred_proba = y_pred_proba_raw[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = y_pred_proba_raw[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = y_pred \n",
    "    \n",
    "    y_test_int = y_test.astype(int)\n",
    "    y_pred_int = y_pred.astype(int)\n",
    "    \n",
    "    test_f1 = f1_score(y_test_int, y_pred_int, average='weighted')\n",
    "    test_accuracy = accuracy_score(y_test_int, y_pred_int)\n",
    "    test_precision = precision_score(y_test_int, y_pred_int, average='weighted')\n",
    "    test_recall = recall_score(y_test_int, y_pred_int, average='weighted')\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    model_performance_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"F1-Score\": test_f1,\n",
    "        \"Accuracy\": test_accuracy,\n",
    "        \"Precision\": test_precision,\n",
    "        \"Recall\": test_recall,\n",
    "        \"AUC-ROC\": test_auc,\n",
    "        \"Best Params\": str(grid_search.best_params_)\n",
    "    })\n",
    "\n",
    "    report = classification_report(y_test_int, y_pred_int, target_names=['Healthy', 'Parkinsons'])\n",
    "    all_classification_reports += f\"--- Classification Report for {name} ---\\n\"\n",
    "    all_classification_reports += f\"Best Parameters: {grid_search.best_params_}\\n\"\n",
    "    all_classification_reports += report + \"\\n\" + \"=\"*60 + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98c979",
   "metadata": {},
   "source": [
    "### 5. Save and Display Results\n",
    "The performance metrics from all models are compiled into a pandas DataFrame, sorted by F1-score, and saved to a CSV file. The detailed classification reports are saved to a text file. A summary of the performance is also printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7fda10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance summary saved to: parkinsons_analysis_results_gridsearch\\model_performance_summary.csv\n",
      "Detailed classification reports saved to: parkinsons_analysis_results_gridsearch\\classification_reports.txt\n",
      "\n",
      "--- Final Model Performance After GridSearchCV ---\n",
      "                    Model  F1-Score  Accuracy  Precision    Recall   AUC-ROC\n",
      "5           Random Forest  0.939581  0.938776   0.941348  0.938776  0.971847\n",
      "6                 XGBoost  0.901472  0.897959   0.912485  0.897959  0.968468\n",
      "3  Support Vector Machine  0.873596  0.877551   0.873574  0.877551  0.914414\n",
      "1     K-Nearest Neighbors  0.836735  0.836735   0.836735  0.836735  0.779279\n",
      "7           ANN (PyTorch)  0.831462  0.836735   0.829723  0.836735  0.909910\n",
      "0     Logistic Regression  0.822650  0.816327   0.835414  0.816327  0.898649\n",
      "2           Decision Tree  0.822650  0.816327   0.835414  0.816327  0.837838\n",
      "4             Naive Bayes  0.657465  0.632653   0.783633  0.632653  0.760135\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(model_performance_summary).sort_values(by=\"F1-Score\", ascending=False)\n",
    "summary_csv_path = os.path.join(output_dir, 'model_performance_summary.csv')\n",
    "summary_df.to_csv(summary_csv_path, index=False)\n",
    "print(f\"\\nModel performance summary saved to: {summary_csv_path}\")\n",
    "\n",
    "reports_txt_path = os.path.join(output_dir, 'classification_reports.txt')\n",
    "with open(reports_txt_path, 'w') as f:\n",
    "    f.write(all_classification_reports)\n",
    "print(f\"Detailed classification reports saved to: {reports_txt_path}\")\n",
    "\n",
    "print(\"\\n--- Final Model Performance After GridSearchCV ---\")\n",
    "print(summary_df.drop(columns='Best Params').to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d9e31",
   "metadata": {},
   "source": [
    "### 6. Generate and Save Figures\n",
    "This section creates several key visualizations to interpret the results:\n",
    "- **Model Performance Comparison**: A bar plot showing the F1-scores of all tuned models.\n",
    "- **Confusion Matrix**: A heatmap for the best-performing model, showing true vs. predicted labels.\n",
    "- **ROC Curve**: A combined plot comparing the ROC curves and AUC scores for the top 4 models.\n",
    "- **SVM Heatmap**: A heatmap visualizing the performance of the SVM with an RBF kernel across different `C` and `gamma` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b137824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Figures...\n",
      "Model Comparison plot saved to: parkinsons_analysis_results_gridsearch\\model_comparison.png\n",
      "Generating Confusion Matrix for best model...\n",
      "Confusion Matrix saved to: parkinsons_analysis_results_gridsearch\\confusion_matrix_best_model.png\n",
      "Generating Combined ROC Curve Plot...\n",
      "Model Comparison plot saved to: parkinsons_analysis_results_gridsearch\\model_comparison.png\n",
      "Generating Confusion Matrix for best model...\n",
      "Confusion Matrix saved to: parkinsons_analysis_results_gridsearch\\confusion_matrix_best_model.png\n",
      "Generating Combined ROC Curve Plot...\n",
      "ROC Curve Plot saved to: parkinsons_analysis_results_gridsearch\\roc_curve_comparison.png\n",
      "SVM Heatmap saved to: parkinsons_analysis_results_gridsearch\\svm_heatmap.png\n",
      "ROC Curve Plot saved to: parkinsons_analysis_results_gridsearch\\roc_curve_comparison.png\n",
      "SVM Heatmap saved to: parkinsons_analysis_results_gridsearch\\svm_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating Figures...\")\n",
    "\n",
    "# Model Performance Comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='F1-Score', y='Model', data=summary_df, palette='viridis', orient='h', hue='Model', legend=False)\n",
    "plt.title('Comparison of Tuned Model Performance (Test Set F1-Score)', fontsize=16)\n",
    "plt.xlabel('Weighted F1-Score', fontsize=12)\n",
    "plt.ylabel('Model', fontsize=12)\n",
    "plt.xlim(min(0.7, summary_df['F1-Score'].min() * 0.95), 1.0)\n",
    "fig_path = os.path.join(output_dir, 'model_comparison.png')\n",
    "plt.savefig(fig_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Model Comparison plot saved to: {fig_path}\")\n",
    "\n",
    "# Confusion Matrix for the best model\n",
    "try:\n",
    "    print(\"Generating Confusion Matrix for best model...\")\n",
    "    best_model_name = summary_df.iloc[0]['Model']\n",
    "    best_model = best_models[best_model_name]\n",
    "    y_pred_best = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    cm = confusion_matrix(y_test.astype(int), y_pred_best.astype(int))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Healthy', 'Parkinsons'], \n",
    "                yticklabels=['Healthy', 'Parkinsons'])\n",
    "    plt.title(f'Confusion Matrix for Best Model ({best_model_name})', fontsize=16)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    fig_path = os.path.join(output_dir, f'confusion_matrix_best_model.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Confusion Matrix saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate Confusion Matrix: {e}\")\n",
    "\n",
    "# ROC Curve Plot\n",
    "try:\n",
    "    print(\"Generating Combined ROC Curve Plot...\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess (AUC = 0.5)')\n",
    "    \n",
    "    top_4_model_names = summary_df.head(4)['Model'].tolist()\n",
    "    \n",
    "    for model_name in top_4_model_names:\n",
    "        model = best_models[model_name]\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob_raw = model.predict_proba(X_test_scaled)\n",
    "            if len(y_prob_raw.shape) == 2:\n",
    "                y_prob = y_prob_raw[:, 1]\n",
    "            else:\n",
    "                y_prob = y_prob_raw\n",
    "            \n",
    "            fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "            auc_score = roc_auc_score(y_test, y_prob)\n",
    "            \n",
    "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.4f})', lw=2)\n",
    "        else:\n",
    "            print(f\"Skipping ROC for {model_name} (no predict_proba method)\")\n",
    "\n",
    "    plt.title('ROC Curve Comparison for Top Models', fontsize=16)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    fig_path = os.path.join(output_dir, 'roc_curve_comparison.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"ROC Curve Plot saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate ROC Curve Plot: {e}\")\n",
    "\n",
    "# SVM Heatmap\n",
    "if svm_grid_search_results:\n",
    "    try:\n",
    "        cv_results = pd.DataFrame(svm_grid_search_results.cv_results_)\n",
    "        rbf_results = cv_results[cv_results['param_kernel'] == 'rbf'].copy()\n",
    "        \n",
    "        if not rbf_results.empty:\n",
    "            rbf_results = rbf_results[pd.to_numeric(rbf_results['param_gamma'], errors='coerce').notna()]\n",
    "            rbf_results['param_C'] = pd.to_numeric(rbf_results['param_C'])\n",
    "            rbf_results['param_gamma'] = pd.to_numeric(rbf_results['param_gamma'])\n",
    "            \n",
    "            pivoted_results = rbf_results.pivot(index='param_C', columns='param_gamma', values='mean_test_score')\n",
    "            pivoted_results = pivoted_results.astype(float)\n",
    "\n",
    "            plt.figure(figsize=(14, 9))\n",
    "            sns.heatmap(pivoted_results, annot=True, fmt=\".4f\", cmap='plasma', linewidths=.5)\n",
    "            plt.title('SVM (RBF Kernel) Performance Heatmap (F1-Score)', fontsize=16)\n",
    "            plt.xlabel('Gamma (Î³)', fontsize=12)\n",
    "            plt.ylabel('Regularization (C)', fontsize=12)\n",
    "            fig_path = os.path.join(output_dir, 'svm_heatmap.png')\n",
    "            plt.savefig(fig_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"SVM Heatmap saved to: {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate SVM heatmap: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13710374",
   "metadata": {},
   "source": [
    "### 7. Model Interpretability\n",
    "To understand *why* the models are making their predictions, this section generates feature importance plots.\n",
    "- For linear models (Logistic Regression, linear SVM), the coefficients are used.\n",
    "- For tree-based models (Decision Tree, Random Forest), the built-in `feature_importances_` attribute is used.\n",
    "- For non-linear \"black box\" models (KNN, RBF SVM, ANN), **Permutation Importance** is calculated. This method measures how much the model's performance decreases when a single feature's values are randomly shuffled, indicating its importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3a9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Model Interpretability Plots ---\n",
      "Generating Feature Importance for Logistic Regression...\n",
      "Logistic Regression Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_logreg.png\n",
      "Generating Feature Importance for Naive Bayes...\n",
      "Logistic Regression Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_logreg.png\n",
      "Generating Feature Importance for Naive Bayes...\n",
      "Naive Bayes Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_naive_bayes.png\n",
      "Generating Permutation Importance for K-Nearest Neighbors...\n",
      "Naive Bayes Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_naive_bayes.png\n",
      "Generating Permutation Importance for K-Nearest Neighbors...\n",
      "KNN Permutation Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_knn.png\n",
      "Generating Permutation Importance for Support Vector Machine...\n",
      "KNN Permutation Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_knn.png\n",
      "Generating Permutation Importance for Support Vector Machine...\n",
      "SVM Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_svm.png\n",
      "Generating Feature Importance for Decision Tree...\n",
      "SVM Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_svm.png\n",
      "Generating Feature Importance for Decision Tree...\n",
      "Decision Tree Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_dt.png\n",
      "Generating Feature Importance for Random Forest...\n",
      "Decision Tree Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_dt.png\n",
      "Generating Feature Importance for Random Forest...\n",
      "Random Forest Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_rf.png\n",
      "Generating Feature Importance for XGBoost...\n",
      "Random Forest Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_rf.png\n",
      "Generating Feature Importance for XGBoost...\n",
      "XGBoost Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_xgb.png\n",
      "Generating Permutation Importance for ANN (PyTorch)...\n",
      "XGBoost Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_xgb.png\n",
      "Generating Permutation Importance for ANN (PyTorch)...\n",
      "ANN (PyTorch) Permutation Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_ann_pytorch.png\n",
      "ANN (PyTorch) Permutation Importance plot saved to: parkinsons_analysis_results_gridsearch\\feature_importance_ann_pytorch.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Generating Model Interpretability Plots ---\")\n",
    "\n",
    "# Logistic Regression Feature Importance\n",
    "try:\n",
    "    print(\"Generating Feature Importance for Logistic Regression...\")\n",
    "    log_reg_model = best_models['Logistic Regression']\n",
    "    if hasattr(log_reg_model, 'coef_'):\n",
    "        log_reg_importance = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': log_reg_model.coef_[0]\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=log_reg_importance, palette='coolwarm', hue='Feature', legend=False)\n",
    "        plt.title('Feature Importance (Coefficients) from Logistic Regression', fontsize=16)\n",
    "        plt.xlabel('Coefficient Value', fontsize=12)\n",
    "        plt.ylabel('Feature', fontsize=12)\n",
    "        fig_path = os.path.join(output_dir, 'feature_importance_logreg.png')\n",
    "        plt.savefig(fig_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Logistic Regression Importance plot saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate Logistic Regression importance plot: {e}\")\n",
    "\n",
    "# Naive Bayes Feature Importance\n",
    "try:\n",
    "    print(\"Generating Feature Importance for Naive Bayes...\")\n",
    "    nb_model = best_models['Naive Bayes']\n",
    "    nb_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance (Mean Diff)': np.abs(nb_model.theta_[1] - nb_model.theta_[0])\n",
    "    }).sort_values(by='Importance (Mean Diff)', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance (Mean Diff)', y='Feature', data=nb_importance.head(10), palette='muted', hue='Feature', legend=False)\n",
    "    plt.title('Top 10 Feature Importance (Absolute Mean Difference) from Naive Bayes', fontsize=16)\n",
    "    plt.xlabel('Absolute Difference in Feature Means', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    fig_path = os.path.join(output_dir, 'feature_importance_naive_bayes.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Naive Bayes Importance plot saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate Naive Bayes importance plot: {e}\")\n",
    "\n",
    "# Permutation Importance for KNN\n",
    "try:\n",
    "    print(\"Generating Permutation Importance for K-Nearest Neighbors...\")\n",
    "    knn_model = best_models['K-Nearest Neighbors']\n",
    "    perm_importance_knn = permutation_importance(\n",
    "        knn_model, X_test_scaled, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    knn_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': perm_importance_knn.importances_mean\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=knn_importance.head(10), palette='plasma', hue='Feature', legend=False)\n",
    "    plt.title('Top 10 Feature Importance (Permutation) from KNN', fontsize=16)\n",
    "    plt.xlabel('Permutation Importance Mean', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    fig_path = os.path.join(output_dir, 'feature_importance_knn.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"KNN Permutation Importance plot saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate KNN importance plot: {e}\")\n",
    "\n",
    "# Permutation Importance for SVM\n",
    "try:\n",
    "    print(\"Generating Permutation Importance for Support Vector Machine...\")\n",
    "    svm_model = best_models['Support Vector Machine']\n",
    "    \n",
    "    if svm_model.kernel == 'linear':\n",
    "        svm_importance = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': svm_model.coef_[0]\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        title = 'Feature Importance (Coefficients) from Linear SVM'\n",
    "        xlabel = 'Coefficient Value'\n",
    "    else:\n",
    "        perm_importance_svm = permutation_importance(\n",
    "            svm_model, X_test_scaled, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
    "        )\n",
    "        svm_importance = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': perm_importance_svm.importances_mean\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        title = f'Top 10 Feature Importance (Permutation) from SVM ({svm_model.kernel} kernel)'\n",
    "        xlabel = 'Permutation Importance Mean'\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=svm_importance.head(10), palette='viridis', hue='Feature', legend=False)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    fig_path = os.path.join(output_dir, 'feature_importance_svm.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"SVM Importance plot saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate SVM importance plot: {e}\")\n",
    "\n",
    "# Decision Tree and Random Forest Feature Importance\n",
    "try:\n",
    "    print(\"Generating Feature Importance for Decision Tree...\")\n",
    "    best_dt = best_models['Decision Tree']\n",
    "    importances_dt = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': best_dt.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importances_dt, palette='rocket', hue='Feature', legend=False)\n",
    "    plt.title('Top 10 Feature Importances from Tuned Decision Tree', fontsize=16)\n",
    "    plt.xlabel('Importance Score', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    fig_path = os.path.join(output_dir, 'feature_importance_dt.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Decision Tree Importance plot saved to: {fig_path}\")\n",
    "\n",
    "    print(\"Generating Feature Importance for Random Forest...\")\n",
    "    best_rf = best_models['Random Forest']\n",
    "    importances_rf = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': best_rf.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importances_rf, palette='cividis', hue='Feature', legend=False)\n",
    "    plt.title('Top 10 Feature Importances from Tuned Random Forest', fontsize=16)\n",
    "    plt.xlabel('Importance Score', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    fig_path = os.path.join(output_dir, 'feature_importance_rf.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Random Forest Importance plot saved to: {fig_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate Tree Model importance plots: {e}\")\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "try:\n",
    "    print(\"Generating Feature Importance for XGBoost...\")\n",
    "    best_xgb = best_models['XGBoost']\n",
    "    importances_xgb = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': best_xgb.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importances_xgb, palette='magma', hue='Feature', legend=False)\n",
    "    plt.title('Top 10 Feature Importances from Tuned XGBoost', fontsize=16)\n",
    "    plt.xlabel('Importance Score', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    fig_path = os.path.join(output_dir, 'feature_importance_xgb.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"XGBoost Importance plot saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate XGBoost importance plot: {e}\")\n",
    "\n",
    "# Permutation Importance for ANN (PyTorch)\n",
    "try:\n",
    "    print(\"Generating Permutation Importance for ANN (PyTorch)...\")\n",
    "    ann_model = best_models['ANN (PyTorch)']\n",
    "    \n",
    "    perm_importance_ann = permutation_importance(\n",
    "        ann_model, X_test_scaled, y_test, n_repeats=10, random_state=42, \n",
    "        n_jobs=1,  # Use 1 core to avoid potential pickling errors with complex objects\n",
    "        scoring='f1_weighted'\n",
    "    )\n",
    "    ann_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': perm_importance_ann.importances_mean\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=ann_importance.head(10), palette='plasma', hue='Feature', legend=False)\n",
    "    plt.title('Top 10 Feature Importance (Permutation) from ANN (PyTorch)', fontsize=16)\n",
    "    plt.xlabel('Permutation Importance Mean (F1-Score Drop)', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    fig_path = os.path.join(output_dir, 'feature_importance_ann_pytorch.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"ANN (PyTorch) Permutation Importance plot saved to: {fig_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate ANN (PyTorch) importance plot: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26c888",
   "metadata": {},
   "source": [
    "### 8. Save Final Model\n",
    "Finally, the best overall model (based on F1-score) and the `StandardScaler` are saved to disk using `joblib`. For the PyTorch model, `skorch` provides a `save_params` method to save the learned weights, as saving the entire model object can be problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f372d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Final Model and Scaler ---\n",
      "Final best model (Random Forest) saved to best_model_Random_Forest.pkl\n",
      "Scaler saved to scaler.pkl\n",
      "\n",
      "Analysis complete. All artifacts have been saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Saving Final Model and Scaler ---\")\n",
    "try:\n",
    "    best_model_name = summary_df.iloc[0]['Model'] \n",
    "    final_model = best_models[best_model_name]\n",
    "    model_filename = f'best_model_{best_model_name.replace(\" \", \"_\")}.pkl'\n",
    "    \n",
    "    if best_model_name == 'ANN (PyTorch)':\n",
    "        # For skorch models, save the parameters instead of the whole object\n",
    "        final_model.save_params(f_params=f'{model_filename}_params.pkl')\n",
    "        print(f\"Final best model ({best_model_name}) PARAMS saved to {model_filename}_params.pkl\")\n",
    "    else:\n",
    "        joblib.dump(final_model, model_filename)\n",
    "        print(f\"Final best model ({best_model_name}) saved to {model_filename}\")\n",
    "\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    print(\"Scaler saved to scaler.pkl\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save final model: {e}\")\n",
    "\n",
    "print(\"\\nAnalysis complete. All artifacts have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
